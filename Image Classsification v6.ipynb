{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path, PureWindowsPath\n",
    "from itertools import islice\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify the top level folder with the labelled images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "/Users/Neil/Library/Mobile Documents/com~apple~CloudDocs/Image Labelling/07 Labelled Images/2018/GP06-Mona/3-McL Monaco 2018 Day 3/labelled_images.csv\n"
     ]
    }
   ],
   "source": [
    "# Mac:\n",
    "# csv_root = Path('/Users/Neil/Dropbox/Documents/Apple and Python Scripts/F1 Image Labelling Py/07 Labelled Images/2018/GP03-Chin/3-McL China 2018 Day 4')\n",
    "# csv_root = Path('/Users/Neil/Dropbox/Documents/Apple and Python Scripts/F1 Image Labelling Py/07 Labelled Images')\n",
    "csv_root = Path('/Users/Neil/Library/Mobile Documents/com~apple~CloudDocs/Image Labelling/07 Labelled Images')\n",
    "\n",
    "# Windows\n",
    "# csv_root = Path(r'C:\\Users\\neil.cameron\\OneDrive - McLaren Technology Group\\07 Labelled Images\\2018\\GP03-Chin\\3-McL China 2018 Day 4')\n",
    "# csv_root = Path(r'C:\\Users\\neil.cameron\\OneDrive - McLaren Technology Group\\07 Labelled Images')\n",
    "\n",
    "# Digital Ocean:\n",
    "# csv_root = Path('/home/neil/datascience/imagelbl/07 Labelled Images/2018/GP03-Chin/3-McL China 2018 Day 4')\n",
    "# csv_root = Path('/home/neil/datascience/imagelbl/07 Labelled Images')\n",
    "\n",
    "csv_lst = list(csv_root.glob('**/labelled_images.csv'))\n",
    "print(len(csv_lst))\n",
    "print(csv_lst[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function for reading each csv file and building a list of file paths and labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(load_file):\n",
    "    '''\n",
    "    Make some python lists of the paths and labels from an image labelling csv\n",
    "    '''\n",
    "    original_images_list = []\n",
    "    scaled_images_list = []\n",
    "    lbl_list_fr_file = []\n",
    "\n",
    "    with open(load_file) as file:\n",
    "        read_file = csv.reader(file, delimiter=',')\n",
    "        for row in islice(read_file, 1, None):\n",
    "            labels_content = row[3:][0].split(', ') # Take the comma separated values for label and split them into a list\n",
    "            if labels_content[0]: # Only include images that have at least one label\n",
    "                lbl_list_fr_file.append(labels_content)\n",
    "                original_images_list.append(row[1])\n",
    "                scaled_images_list.append(row[2])                \n",
    "    return(original_images_list, scaled_images_list, lbl_list_fr_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_images_list = []\n",
    "scaled_images_list = []\n",
    "lbl_list_fr_file = []\n",
    "\n",
    "for file in csv_lst:    \n",
    "    original_images_list_add, scaled_images_list_add, lbl_list_fr_file_add = read_file(file)\n",
    "    original_images_list.extend(original_images_list_add)\n",
    "    scaled_images_list.extend(scaled_images_list_add)\n",
    "    lbl_list_fr_file.extend(lbl_list_fr_file_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3258\n",
      "\\\\mrl-plfile01\\Aero\\Track Photos\\2018\\GP06-Mona\\Competitor\\3-McL Monaco 2018 Day 3\\07-Haas\\_MC16829.JPG\n",
      "C:\\Users\\neil.cameron\\OneDrive - McLaren Technology Group\\07 Labelled Images\\2018\\GP06-Mona\\3-McL Monaco 2018 Day 3\\07-Haas\\_MC16829.JPG\n",
      "['Above']\n"
     ]
    }
   ],
   "source": [
    "# An example of the output in the labels list\n",
    "print(len(scaled_images_list))\n",
    "print(original_images_list[0])\n",
    "print(scaled_images_list[0])\n",
    "print(lbl_list_fr_file[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter down the list of images and build an array of dictionary entries with paths to pictures for analysis vs labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Scaled Image Path': 'C:\\\\Users\\\\neil.cameron\\\\OneDrive - McLaren Technology Group\\\\07 Labelled Images\\\\2018\\\\GP01-Astl\\\\3-McL Australia 2018 Day 4\\\\05-Williams\\\\_AU14633.JPG', 'Team Name': 'Williams', 'Team': 5}\n",
      "1670\n"
     ]
    }
   ],
   "source": [
    "# Set these arrays to filter the training images down to only specific matches\n",
    "# ['Front_Wing', 'Rear_Wing', 'Chassis', 'Front_Suspension', 'Rear_Suspension', 'Floor', 'Engine', 'Maincase', 'Internals', 'Front_Brake_Duct', 'Rear_Brake_Duct', 'Ride_Height', 'Dead_Rear', 'Above', 'Garage', 'Track', 'Pick']\n",
    "lbls_to_match = ['Ride_Height', 'Dead_Rear', 'Above', 'Track', 'Front_Wing', 'Rear_Wing']\n",
    "teams_lst = ['Mercedes', 'Red_Bull', 'Ferrari', 'Force_India', 'Williams', 'McLaren', 'Haas', 'Torro_Rosso', 'Renault', 'Sauber']\n",
    "\n",
    "# Translation dictionary from teams to ints\n",
    "#dict = {'Mercedes':1, 'Red_Bull':2, 'Ferrari':3, 'Force_India':4, 'Williams':5, 'McLaren':6, 'Haas':7, 'Torro_Rosso':8, 'Renault':9, 'Sauber':0}\n",
    "teams_dict_vals = list(range(1,10))\n",
    "teams_dict_vals.append(0)\n",
    "teams_dict = dict(zip(teams_lst, teams_dict_vals))\n",
    "\n",
    "keys = ['Scaled Image Path', 'Team Name', 'Team']\n",
    "path_label_dictlist = []\n",
    "\n",
    "for i, item in enumerate(lbl_list_fr_file):\n",
    "    if list(set(item).intersection(lbls_to_match)) and list(set(item).intersection(teams_lst)): # Only items with lables in common with the lbls_to_match\n",
    "        team_name = list(set(item).intersection(teams_lst)) # Only lables that intersect with team labels\n",
    "        team = teams_dict[team_name[0]]\n",
    "        path_label_dictlist.append({keys[0]: scaled_images_list[i], keys[1]: team_name[0], keys[2]: team})\n",
    "        \n",
    "print(path_label_dictlist[1])\n",
    "print(len(path_label_dictlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make the image path independent of operating system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def repath(path, csv_root):\n",
    "#     '''\n",
    "#     Take some hard-coded paths (like in a labeled images csv document) and point them to a new root. This is needed to run this script on different operating systems where the scaled images are stored in a different location than where the initial image labelling was done.\n",
    "#     '''    \n",
    "#     csv_root_lst = list(csv_root.parts)\n",
    "#     path_lst = list(Path(path).parts)\n",
    "#     remainder = Path(*[item for item in path_lst if item not in csv_root_lst])\n",
    "#     output_path = Path(csv_root, remainder)\n",
    "#     return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for taking the scaled image paths and converting them for Mac\n",
    "def repath(path, csv_root):   \n",
    "    csv_root_lst = list(csv_root.parts)\n",
    "    path_lst = list(PureWindowsPath(path).parts)\n",
    "    fr = (path_lst.index('07 Labelled Images')+1)\n",
    "    path_lst = path_lst[fr:]\n",
    "    remainder = Path(*[item for item in path_lst])\n",
    "    output_path = Path(csv_root, remainder)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Scaled Image Path': 'C:\\\\Users\\\\neil.cameron\\\\OneDrive - McLaren Technology Group\\\\07 Labelled Images\\\\2018\\\\GP01-Astl\\\\3-McL Australia 2018 Day 4\\\\05-Williams\\\\_AU14633.JPG', 'Team Name': 'Williams', 'Team': 5}\n",
      "{'Scaled Image Path': PosixPath('/Users/Neil/Library/Mobile Documents/com~apple~CloudDocs/Image Labelling/07 Labelled Images/2018/GP01-Astl/3-McL Australia 2018 Day 4/05-Williams/_AU14633.JPG'), 'Team Name': 'Williams', 'Team': 5}\n"
     ]
    }
   ],
   "source": [
    "print(path_label_dictlist[1])\n",
    "#x = repath(path_label_dictlist[1]['Scaled Image Path'], csv_root)\n",
    "for item in path_label_dictlist:\n",
    "    item['Scaled Image Path'] = repath(item['Scaled Image Path'], csv_root)\n",
    "print(path_label_dictlist[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Further resizing of image data and stack it as an np array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG (1000, 665) RGB\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "im = Image.open(path_label_dictlist[1]['Scaled Image Path'])\n",
    "#im.show()\n",
    "print(im.format, im.size, im.mode) # Details before resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(path, size):\n",
    "    '''\n",
    "    Scaled an image at a specific path down to a square of a specific size\n",
    "    '''\n",
    "    im = Image.open(path)\n",
    "    resized = np.array(im.resize((size, size), resample=Image.LANCZOS))\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size = 50\n",
    "im_stack = []\n",
    "lbl_stack = []\n",
    "for row in path_label_dictlist:\n",
    "    im_stack.append(resize(Path(row['Scaled Image Path']), new_size))\n",
    "    lbl_stack.append(row['Team'])\n",
    "im_stack = np.array(im_stack)\n",
    "lbl_stack = np.array(lbl_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1670, 50, 50, 3)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(im_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffle and train test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1670, 50, 50, 3)\n",
      "(1670,)\n"
     ]
    }
   ],
   "source": [
    "#np.random.shuffle(im_stack)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "im_stack, lbl_stack = shuffle(im_stack, lbl_stack, random_state=0)\n",
    "print(np.shape(im_stack))\n",
    "print(np.shape(lbl_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1169\n",
      "501\n"
     ]
    }
   ],
   "source": [
    "test_percent = 0.3\n",
    "no_images = int(np.shape(im_stack)[0])\n",
    "train_slice = int((1-test_percent)*no_images)\n",
    "test_slice = no_images - train_slice\n",
    "print(train_slice)\n",
    "print(test_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1169, 50, 50, 3) and (1169,)\n"
     ]
    }
   ],
   "source": [
    "im_stack_train = im_stack[:train_slice]\n",
    "lbl_stack_train = lbl_stack[:train_slice]\n",
    "im_stack_test = im_stack[-test_slice:]\n",
    "lbl_stack_test = lbl_stack[-test_slice:]\n",
    "print('{0} and {1}'.format(str(np.shape(im_stack_train)), str(np.shape(lbl_stack_train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Open an expample image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ae6c8c048>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(im_stack[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(vec, vals=len(teams_lst)):\n",
    "    '''\n",
    "    One-hot encodes all of the possible labels\n",
    "    '''\n",
    "    n = len(vec)\n",
    "    out = np.zeros((n, vals))\n",
    "    out[range(n), vec] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageBatcher():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "        \n",
    "        self.im_stack_train = im_stack_train\n",
    "        self.lbl_stack_train = lbl_stack_train\n",
    "        self.im_stack_test = im_stack_test\n",
    "        self.lbl_stack_test = lbl_stack_test        \n",
    "        \n",
    "        print(np.shape(lbl_stack_train))\n",
    "    \n",
    "    def set_up_images(self):\n",
    "        \n",
    "        print(\"Setting Up Training Images and Labels\")\n",
    "        train_len = len(self.im_stack_train)\n",
    "        self.im_stack_train = im_stack_train/255\n",
    "        self.lbl_stack_train = one_hot_encode(lbl_stack_train)#, 10)\n",
    "        \n",
    "        print(np.shape(self.lbl_stack_train))\n",
    "        \n",
    "        print(\"Setting Up Test Images and Labels\")\n",
    "        test_len = len(self.im_stack_test)\n",
    "        self.im_stack_test = im_stack_test/255\n",
    "        self.lbl_stack_test = one_hot_encode(lbl_stack_test)#, 10)\n",
    "                \n",
    "    def next_batch(self, batch_size):\n",
    "        x = self.im_stack_train[self.i:self.i+batch_size]\n",
    "        y = self.lbl_stack_train[self.i:self.i+batch_size]\n",
    "        self.i = (self.i + batch_size) % len(self.im_stack_train)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1169,)\n",
      "Setting Up Training Images and Labels\n",
      "(1169, 10)\n",
      "Setting Up Test Images and Labels\n"
     ]
    }
   ],
   "source": [
    "# Before Your tf.Session run these two lines\n",
    "ib = ImageBatcher()\n",
    "ib.set_up_images()\n",
    "\n",
    "# During your session to grab the next batch use this line\n",
    "# batch = ib.next_batch(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Model helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,new_size,new_size,3])\n",
    "y_true = tf.placeholder(tf.float32,shape=[None,len(teams_lst)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder to hold a single probability for the dropout\n",
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the network\n",
    "\n",
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    \n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Creating the Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 50, 50, 32)\n",
      "(?, 25, 25, 32)\n"
     ]
    }
   ],
   "source": [
    "convo_1 = convolutional_layer(x,shape=[4,4,3,32]) # Size x size of filer, number of input channels, number of features out\n",
    "print(np.shape(convo_1))\n",
    "convo_1_pooling = max_pool_2by2(convo_1)\n",
    "print(np.shape(convo_1_pooling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 25, 25, 64)\n",
      "(?, 13, 13, 64)\n"
     ]
    }
   ],
   "source": [
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[4,4,32,64]) # Size x size of filer, number of input channels from previous layer, number of features out\n",
    "print(np.shape(convo_2))\n",
    "convo_2_pooling = max_pool_2by2(convo_2)\n",
    "print(np.shape(convo_2_pooling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10816)\n"
     ]
    }
   ],
   "source": [
    "convo_2_flat = tf.reshape(convo_2_pooling,[-1, 13*13*64]) #108160]) # Fully connected output 13 x 13 x 64 for 50x50, 25 x 25 x 64 for 100x100\n",
    "print(np.shape(convo_2_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 512)\n"
     ]
    }
   ],
   "source": [
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,512)) # Your choice of how many neurons in final layer - 512 is good\n",
    "print(np.shape(full_layer_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 512)\n"
     ]
    }
   ],
   "source": [
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)\n",
    "print(np.shape(full_one_dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout,10)\n",
    "print(np.shape(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss function and optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on step 0\n",
      "Accuracy is:\n",
      "0.20958084\n",
      "\n",
      "\n",
      "Currently on step 100\n",
      "Accuracy is:\n",
      "0.3752495\n",
      "\n",
      "\n",
      "Currently on step 200\n",
      "Accuracy is:\n",
      "0.4251497\n",
      "\n",
      "\n",
      "Currently on step 300\n",
      "Accuracy is:\n",
      "0.4770459\n",
      "\n",
      "\n",
      "Currently on step 400\n",
      "Accuracy is:\n",
      "0.5249501\n",
      "\n",
      "\n",
      "Currently on step 500\n",
      "Accuracy is:\n",
      "0.55688626\n",
      "\n",
      "\n",
      "Currently on step 600\n",
      "Accuracy is:\n",
      "0.5708583\n",
      "\n",
      "\n",
      "Currently on step 700\n",
      "Accuracy is:\n",
      "0.61676645\n",
      "\n",
      "\n",
      "Currently on step 800\n",
      "Accuracy is:\n",
      "0.6307385\n",
      "\n",
      "\n",
      "Currently on step 900\n",
      "Accuracy is:\n",
      "0.61077845\n",
      "\n",
      "\n",
      "Currently on step 1000\n",
      "Accuracy is:\n",
      "0.6546906\n",
      "\n",
      "\n",
      "Currently on step 1100\n",
      "Accuracy is:\n",
      "0.66866267\n",
      "\n",
      "\n",
      "Currently on step 1200\n",
      "Accuracy is:\n",
      "0.6966068\n",
      "\n",
      "\n",
      "Currently on step 1300\n",
      "Accuracy is:\n",
      "0.6606786\n",
      "\n",
      "\n",
      "Currently on step 1400\n",
      "Accuracy is:\n",
      "0.6766467\n",
      "\n",
      "\n",
      "Currently on step 1500\n",
      "Accuracy is:\n",
      "0.6826347\n",
      "\n",
      "\n",
      "Currently on step 1600\n",
      "Accuracy is:\n",
      "0.66267467\n",
      "\n",
      "\n",
      "Currently on step 1700\n",
      "Accuracy is:\n",
      "0.6766467\n",
      "\n",
      "\n",
      "Currently on step 1800\n",
      "Accuracy is:\n",
      "0.66267467\n",
      "\n",
      "\n",
      "Currently on step 1900\n",
      "Accuracy is:\n",
      "0.7085828\n",
      "\n",
      "\n",
      "Currently on step 2000\n",
      "Accuracy is:\n",
      "0.68063873\n",
      "\n",
      "\n",
      "Currently on step 2100\n",
      "Accuracy is:\n",
      "0.6926148\n",
      "\n",
      "\n",
      "Currently on step 2200\n",
      "Accuracy is:\n",
      "0.7085828\n",
      "\n",
      "\n",
      "Currently on step 2300\n",
      "Accuracy is:\n",
      "0.71057886\n",
      "\n",
      "\n",
      "Currently on step 2400\n",
      "Accuracy is:\n",
      "0.72255486\n",
      "\n",
      "\n",
      "Currently on step 2500\n",
      "Accuracy is:\n",
      "0.73852295\n",
      "\n",
      "\n",
      "Currently on step 2600\n",
      "Accuracy is:\n",
      "0.69061875\n",
      "\n",
      "\n",
      "Currently on step 2700\n",
      "Accuracy is:\n",
      "0.7145709\n",
      "\n",
      "\n",
      "Currently on step 2800\n",
      "Accuracy is:\n",
      "0.7085828\n",
      "\n",
      "\n",
      "Currently on step 2900\n",
      "Accuracy is:\n",
      "0.7285429\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(3000):\n",
    "        batch = ib.next_batch(10)\n",
    "        #print(np.shape(batch[0]))\n",
    "        #print(np.shape(batch[1]))\n",
    "        sess.run(train, feed_dict={x: batch[0], y_true: batch[1], hold_prob: 0.5})\n",
    "        \n",
    "        # Print progress every 100 steps\n",
    "        if i%100 == 0:\n",
    "            \n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is:')\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "            print(sess.run(acc,feed_dict={x:ib.im_stack_test, y_true:ib.lbl_stack_test, hold_prob:1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
