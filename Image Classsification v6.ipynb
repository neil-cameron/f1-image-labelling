{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify the top level folder with the labelled images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "C:\\Users\\neil.cameron\\OneDrive - McLaren Technology Group\\07 Labelled Images\\2018\\GP01-Astl\\1-McL Australia 2018 Day 1\\labeled_images.csv\n"
     ]
    }
   ],
   "source": [
    "# Mac:\n",
    "# csv_root = Path('/Users/Neil/Dropbox/Documents/Apple and Python Scripts/F1 Image Labelling Py/07 Labelled Images/2018/GP03-Chin/3-McL China 2018 Day 4')\n",
    "# csv_root = Path('/Users/Neil/Dropbox/Documents/Apple and Python Scripts/F1 Image Labelling Py/07 Labelled Images')\n",
    "\n",
    "# Windows\n",
    "# csv_root = Path(r'C:\\Users\\neil.cameron\\OneDrive - McLaren Technology Group\\07 Labelled Images\\2018\\GP03-Chin\\3-McL China 2018 Day 4')\n",
    "csv_root = Path(r'C:\\Users\\neil.cameron\\OneDrive - McLaren Technology Group\\07 Labelled Images')\n",
    "\n",
    "# Digital Ocean:\n",
    "# csv_root = Path('/home/neil/datascience/imagelbl/07 Labelled Images/2018/GP03-Chin/3-McL China 2018 Day 4')\n",
    "# csv_root = Path('/home/neil/datascience/imagelbl/07 Labelled Images')\n",
    "\n",
    "csv_lst = list(csv_root.glob('**/labeled_images.csv'))\n",
    "print(len(csv_lst))\n",
    "print(csv_lst[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function for reading each csv file and building a list of file paths and labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(load_file):\n",
    "    '''\n",
    "    Make some python lists of the paths and labels from an image labelling csv\n",
    "    '''\n",
    "    original_images_list = []\n",
    "    scaled_images_list = []\n",
    "    lbl_list_fr_file = []\n",
    "\n",
    "    with open(load_file) as file:\n",
    "        read_file = csv.reader(file, delimiter=',')\n",
    "        for row in islice(read_file, 1, None):\n",
    "            labels_content = row[3:][0].split(', ') # Take the comma separated values for label and split them into a list\n",
    "            if labels_content[0]: # Only include images that have at least one label\n",
    "                lbl_list_fr_file.append(labels_content)\n",
    "                original_images_list.append(row[1])\n",
    "                scaled_images_list.append(row[2])                \n",
    "    return(original_images_list, scaled_images_list, lbl_list_fr_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_images_list = []\n",
    "scaled_images_list = []\n",
    "lbl_list_fr_file = []\n",
    "\n",
    "for file in csv_lst:    \n",
    "    original_images_list_add, scaled_images_list_add, lbl_list_fr_file_add = read_file(file)\n",
    "    original_images_list.extend(original_images_list_add)\n",
    "    scaled_images_list.extend(scaled_images_list_add)\n",
    "    lbl_list_fr_file.extend(lbl_list_fr_file_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2229\n",
      "\\\\mrl-plfile01\\Aero\\Track Photos\\2018\\GP01-Astl\\3-McL Australia 2018 Day 3\\07-Haas\\_BT15743.JPG\n",
      "C:\\Users\\neil.cameron\\OneDrive - McLaren Technology Group\\07 Labelled Images\\2018\\GP01-Astl\\3-McL Australia 2018 Day 3\\07-Haas\\_BT15743.JPG\n",
      "['Haas', 'Front_Suspension', 'Garage']\n"
     ]
    }
   ],
   "source": [
    "# An example of the output in the labels list\n",
    "print(len(scaled_images_list))\n",
    "print(original_images_list[0])\n",
    "print(scaled_images_list[0])\n",
    "print(lbl_list_fr_file[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter down the list of images and build an array of dictionary entries with paths to pictures for analysis vs labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Scaled Image Path': 'C:\\\\Users\\\\neil.cameron\\\\OneDrive - McLaren Technology Group\\\\07 Labelled Images\\\\2018\\\\GP01-Astl\\\\3-McL Australia 2018 Day 3\\\\07-Haas\\\\_BT15787.JPG', 'Team Name': 'Haas', 'Team': 7}\n",
      "945\n"
     ]
    }
   ],
   "source": [
    "# Set these arrays to filter the training images down to only specific matches\n",
    "# ['Front_Wing', 'Rear_Wing', 'Chassis', 'Front_Suspension', 'Rear_Suspension', 'Floor', 'Engine', 'Maincase', 'Internals', 'Front_Brake_Duct', 'Rear_Brake_Duct', 'Ride_Height', 'Dead_Rear', 'Above', 'Garage', 'Track', 'Pick']\n",
    "lbls_to_match = ['Ride_Height', 'Dead_Rear', 'Above', 'Track', 'Front_Wing', 'Rear_Wing']\n",
    "teams_lst = ['Mercedes', 'Red_Bull', 'Ferrari', 'Force_India', 'Williams', 'McLaren', 'Haas', 'Torro_Rosso', 'Renault', 'Sauber']\n",
    "\n",
    "# Translation dictionary from teams to ints\n",
    "#dict = {'Mercedes':1, 'Red_Bull':2, 'Ferrari':3, 'Force_India':4, 'Williams':5, 'McLaren':6, 'Haas':7, 'Torro_Rosso':8, 'Renault':9, 'Sauber':0}\n",
    "teams_dict_vals = list(range(1,10))\n",
    "teams_dict_vals.append(0)\n",
    "teams_dict = dict(zip(teams_lst, teams_dict_vals))\n",
    "\n",
    "keys = ['Scaled Image Path', 'Team Name', 'Team']\n",
    "path_label_dictlist = []\n",
    "\n",
    "for i, item in enumerate(lbl_list_fr_file):\n",
    "    if list(set(item).intersection(lbls_to_match)) and list(set(item).intersection(teams_lst)): # Only items with lables in common with the lbls_to_match\n",
    "        team_name = list(set(item).intersection(teams_lst)) # Only lables that intersect with team labels\n",
    "        team = teams_dict[team_name[0]]\n",
    "        path_label_dictlist.append({keys[0]: scaled_images_list[i], keys[1]: team_name[0], keys[2]: team})\n",
    "        \n",
    "print(path_label_dictlist[1])\n",
    "print(len(path_label_dictlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make the image path independent of operating system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repath(path, csv_root):\n",
    "    '''\n",
    "    Take some hard-coded paths (like in a labeled images csv document) and point them to a new root. This is needed to run this script on different operating systems where the scaled images are stored in a different location than where the initial image labelling was done.\n",
    "    '''    \n",
    "    csv_root_lst = list(csv_root.parts)\n",
    "    path_lst = list(Path(path).parts)\n",
    "    remainder = Path(*[item for item in path_lst if item not in csv_root_lst])\n",
    "    output_path = Path(csv_root, remainder)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Scaled Image Path': 'C:\\\\Users\\\\neil.cameron\\\\OneDrive - McLaren Technology Group\\\\07 Labelled Images\\\\2018\\\\GP01-Astl\\\\3-McL Australia 2018 Day 3\\\\07-Haas\\\\_BT15787.JPG', 'Team Name': 'Haas', 'Team': 7}\n",
      "{'Scaled Image Path': WindowsPath('C:/Users/neil.cameron/OneDrive - McLaren Technology Group/07 Labelled Images/2018/GP01-Astl/3-McL Australia 2018 Day 3/07-Haas/_BT15787.JPG'), 'Team Name': 'Haas', 'Team': 7}\n"
     ]
    }
   ],
   "source": [
    "print(path_label_dictlist[1])\n",
    "for item in path_label_dictlist:\n",
    "    item['Scaled Image Path'] = repath(item['Scaled Image Path'], csv_root)\n",
    "print(path_label_dictlist[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Further resizing of image data and stack it as an np array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG (1000, 666) RGB\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "im = Image.open(path_label_dictlist[1]['Scaled Image Path'])\n",
    "#im.show()\n",
    "print(im.format, im.size, im.mode) # Details before resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize(path, size):\n",
    "    '''\n",
    "    Scaled an image at a specific path down to a square of a specific size\n",
    "    '''\n",
    "    im = Image.open(path)\n",
    "    resized = np.array(im.resize((size, size), resample=Image.LANCZOS))\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_size = 50\n",
    "im_stack = []\n",
    "lbl_stack = []\n",
    "for row in path_label_dictlist:\n",
    "    im_stack.append(resize(Path(row['Scaled Image Path']), new_size))\n",
    "    lbl_stack.append(row['Team'])\n",
    "im_stack = np.array(im_stack)\n",
    "lbl_stack = np.array(lbl_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(945, 50, 50, 3)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(im_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shuffle and train test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(945, 50, 50, 3)\n",
      "(945,)\n"
     ]
    }
   ],
   "source": [
    "#np.random.shuffle(im_stack)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "im_stack, lbl_stack = shuffle(im_stack, lbl_stack, random_state=0)\n",
    "print(np.shape(im_stack))\n",
    "print(np.shape(lbl_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661\n",
      "284\n"
     ]
    }
   ],
   "source": [
    "test_percent = 0.3\n",
    "no_images = int(np.shape(im_stack)[0])\n",
    "train_slice = int((1-test_percent)*no_images)\n",
    "test_slice = no_images - train_slice\n",
    "print(train_slice)\n",
    "print(test_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(661, 50, 50, 3) and (661,)\n"
     ]
    }
   ],
   "source": [
    "im_stack_train = im_stack[:train_slice]\n",
    "lbl_stack_train = lbl_stack[:train_slice]\n",
    "im_stack_test = im_stack[-test_slice:]\n",
    "lbl_stack_test = lbl_stack[-test_slice:]\n",
    "print('{0} and {1}'.format(str(np.shape(im_stack_train)), str(np.shape(lbl_stack_train))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Open an expample image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x9ecaef0>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(im_stack[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(vec, vals=len(teams_lst)):\n",
    "    '''\n",
    "    One-hot encodes all of the possible labels\n",
    "    '''\n",
    "    n = len(vec)\n",
    "    out = np.zeros((n, vals))\n",
    "    out[range(n), vec] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImageBatcher():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.i = 0\n",
    "        \n",
    "        self.im_stack_train = im_stack_train\n",
    "        self.lbl_stack_train = lbl_stack_train\n",
    "        self.im_stack_test = im_stack_test\n",
    "        self.lbl_stack_test = lbl_stack_test        \n",
    "        \n",
    "        print(np.shape(lbl_stack_train))\n",
    "    \n",
    "    def set_up_images(self):\n",
    "        \n",
    "        print(\"Setting Up Training Images and Labels\")\n",
    "        train_len = len(self.im_stack_train)\n",
    "        self.im_stack_train = im_stack_train/255\n",
    "        self.lbl_stack_train = one_hot_encode(lbl_stack_train)#, 10)\n",
    "        \n",
    "        print(np.shape(self.lbl_stack_train))\n",
    "        \n",
    "        print(\"Setting Up Test Images and Labels\")\n",
    "        test_len = len(self.im_stack_test)\n",
    "        self.im_stack_test = im_stack_test/255\n",
    "        self.lbl_stack_test = one_hot_encode(lbl_stack_test)#, 10)\n",
    "                \n",
    "    def next_batch(self, batch_size):\n",
    "        x = self.im_stack_train[self.i:self.i+batch_size]\n",
    "        y = self.lbl_stack_train[self.i:self.i+batch_size]\n",
    "        self.i = (self.i + batch_size) % len(self.im_stack_train)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(661,)\n",
      "Setting Up Training Images and Labels\n",
      "(661, 10)\n",
      "Setting Up Test Images and Labels\n"
     ]
    }
   ],
   "source": [
    "# Before Your tf.Session run these two lines\n",
    "ib = ImageBatcher()\n",
    "ib.set_up_images()\n",
    "\n",
    "# During your session to grab the next batch use this line\n",
    "# batch = ib.next_batch(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Model helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,shape=[None,new_size,new_size,3])\n",
    "y_true = tf.placeholder(tf.float32,shape=[None,len(teams_lst)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholder to hold a single probability for the dropout\n",
    "hold_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup the network\n",
    "\n",
    "def init_weights(shape):\n",
    "    init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(init_random_dist)\n",
    "\n",
    "def init_bias(shape):\n",
    "    init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(init_bias_vals)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2by2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def convolutional_layer(input_x, shape):\n",
    "    W = init_weights(shape)\n",
    "    b = init_bias([shape[3]])\n",
    "    return tf.nn.relu(conv2d(input_x, W) + b)\n",
    "\n",
    "def normal_full_layer(input_layer, size):\n",
    "    input_size = int(input_layer.get_shape()[1])\n",
    "    W = init_weights([input_size, size])\n",
    "    b = init_bias([size])\n",
    "    \n",
    "    return tf.matmul(input_layer, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Creating the Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 50, 50, 32)\n",
      "(?, 25, 25, 32)\n"
     ]
    }
   ],
   "source": [
    "convo_1 = convolutional_layer(x,shape=[4,4,3,32]) # Size x size of filer, number of input channels, number of features out\n",
    "print(np.shape(convo_1))\n",
    "convo_1_pooling = max_pool_2by2(convo_1)\n",
    "print(np.shape(convo_1_pooling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 25, 25, 64)\n",
      "(?, 13, 13, 64)\n"
     ]
    }
   ],
   "source": [
    "convo_2 = convolutional_layer(convo_1_pooling,shape=[4,4,32,64]) # Size x size of filer, number of input channels from previous layer, number of features out\n",
    "print(np.shape(convo_2))\n",
    "convo_2_pooling = max_pool_2by2(convo_2)\n",
    "print(np.shape(convo_2_pooling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10816)\n"
     ]
    }
   ],
   "source": [
    "convo_2_flat = tf.reshape(convo_2_pooling,[-1, 13*13*64]) #108160]) # Fully connected output 13 x 13 x 64\n",
    "print(np.shape(convo_2_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 512)\n"
     ]
    }
   ],
   "source": [
    "full_layer_one = tf.nn.relu(normal_full_layer(convo_2_flat,512)) # Your choice of how many neurons in final layer\n",
    "print(np.shape(full_layer_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 512)\n"
     ]
    }
   ],
   "source": [
    "full_one_dropout = tf.nn.dropout(full_layer_one,keep_prob=hold_prob)\n",
    "print(np.shape(full_one_dropout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "y_pred = normal_full_layer(full_one_dropout,10)\n",
    "print(np.shape(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss function and optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true,logits=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on step 0\n",
      "Accuracy is:\n",
      "0.105634\n",
      "\n",
      "\n",
      "Currently on step 100\n",
      "Accuracy is:\n",
      "0.190141\n",
      "\n",
      "\n",
      "Currently on step 200\n",
      "Accuracy is:\n",
      "0.348592\n",
      "\n",
      "\n",
      "Currently on step 300\n",
      "Accuracy is:\n",
      "0.376761\n",
      "\n",
      "\n",
      "Currently on step 400\n",
      "Accuracy is:\n",
      "0.40493\n",
      "\n",
      "\n",
      "Currently on step 500\n",
      "Accuracy is:\n",
      "0.422535\n",
      "\n",
      "\n",
      "Currently on step 600\n",
      "Accuracy is:\n",
      "0.461268\n",
      "\n",
      "\n",
      "Currently on step 700\n",
      "Accuracy is:\n",
      "0.517606\n",
      "\n",
      "\n",
      "Currently on step 800\n",
      "Accuracy is:\n",
      "0.489437\n",
      "\n",
      "\n",
      "Currently on step 900\n",
      "Accuracy is:\n",
      "0.535211\n",
      "\n",
      "\n",
      "Currently on step 1000\n",
      "Accuracy is:\n",
      "0.53169\n",
      "\n",
      "\n",
      "Currently on step 1100\n",
      "Accuracy is:\n",
      "0.538732\n",
      "\n",
      "\n",
      "Currently on step 1200\n",
      "Accuracy is:\n",
      "0.598592\n",
      "\n",
      "\n",
      "Currently on step 1300\n",
      "Accuracy is:\n",
      "0.577465\n",
      "\n",
      "\n",
      "Currently on step 1400\n",
      "Accuracy is:\n",
      "0.626761\n",
      "\n",
      "\n",
      "Currently on step 1500\n",
      "Accuracy is:\n",
      "0.602113\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(1600):\n",
    "        batch = ib.next_batch(10)\n",
    "        #print(np.shape(batch[0]))\n",
    "        #print(np.shape(batch[1]))\n",
    "        sess.run(train, feed_dict={x: batch[0], y_true: batch[1], hold_prob: 0.5})\n",
    "        \n",
    "        # Print progress every 100 steps\n",
    "        if i%100 == 0:\n",
    "            \n",
    "            print('Currently on step {}'.format(i))\n",
    "            print('Accuracy is:')\n",
    "            # Test the Train Model\n",
    "            matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
    "\n",
    "            acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
    "\n",
    "            print(sess.run(acc,feed_dict={x:ib.im_stack_test, y_true:ib.lbl_stack_test, hold_prob:1.0}))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
